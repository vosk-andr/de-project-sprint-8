{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, to_json, col, lit, struct, unix_timestamp, current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "\n",
    "# метод для записи данных в 2 target: в PostgreSQL для фидбэков и в Kafka для триггеров\n",
    "def foreach_batch_function(df, epoch_id):\n",
    "    # сохраняем df в памяти, чтобы не создавать df заново перед отправкой в Kafka\n",
    "    df.cache()\n",
    "\n",
    "    # записываем df в PostgreSQL с полем feedback\n",
    "    df.withColumn(\"feedback\", lit(None)) \\\n",
    "        .write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/de\") \\\n",
    "        .option('driver', 'org.postgresql.Driver') \\\n",
    "        .option(\"dbtable\", \"subscribers_feedback\") \\\n",
    "        .option(\"user\", \"jovyan\") \\\n",
    "        .option(\"password\", \"jovyan\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()\n",
    "\n",
    "    # создаём df для отправки в Kafka. Сериализация в json.\n",
    "    kafka_df = df.select(\n",
    "        to_json(struct(\n",
    "            \"restaurant_id\",\n",
    "            \"adv_campaign_id\",\n",
    "            \"adv_campaign_content\",\n",
    "            \"adv_campaign_owner\",\n",
    "            \"adv_campaign_owner_contact\",\n",
    "            \"adv_campaign_datetime_start\",\n",
    "            \"adv_campaign_datetime_end\",\n",
    "            \"datetime_created\",\n",
    "            \"client_id\",\n",
    "            \"trigger_datetime_created\"\n",
    "        )).alias(\"value\")\n",
    "    )\n",
    "    \n",
    "    # отправляем сообщения в результирующий топик Kafka без поля feedback\n",
    "    kafka_df.write \\\n",
    "        .format('kafka') \\\n",
    "        .option('kafka.bootstrap.servers', 'rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091') \\\n",
    "        .option('topic', 'your_topic_out') \\\n",
    "        .option('kafka.security.protocol', 'SASL_SSL') \\\n",
    "        .option('kafka.sasl.mechanism', 'SCRAM-SHA-512') \\\n",
    "        .option('kafka.sasl.jaas.config', 'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"de-student\" password=\"ltcneltyn\";') \\\n",
    "        .save()\n",
    "    # очищаем память от df\n",
    "    df.unpersist()\n",
    "\n",
    "# необходимые библиотеки для интеграции Spark с Kafka и PostgreSQL\n",
    "spark_jars_packages = \",\".join(\n",
    "        [\n",
    "            \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\",\n",
    "            \"org.postgresql:postgresql:42.4.0\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# создаём spark сессию с необходимыми библиотеками в spark_jars_packages для интеграции с Kafka и PostgreSQL\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RestaurantSubscribeStreamingService\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
    "    .config(\"spark.jars.packages\", spark_jars_packages) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# читаем из топика Kafka сообщения с акциями от ресторанов \n",
    "restaurant_read_stream_df = spark.readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091') \\\n",
    "    .option('kafka.security.protocol', 'SASL_SSL') \\\n",
    "    .option('kafka.sasl.jaas.config', 'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"de-student\" password=\"ltcneltyn\";') \\\n",
    "    .option('kafka.sasl.mechanism', 'SCRAM-SHA-512') \\\n",
    "    .option('subscribe', 'de-student_in') \\\n",
    "    .load()\n",
    "\n",
    "# определяем схему входного сообщения для json\n",
    "incomming_message_schema = StructType([\n",
    "    StructField(\"restaurant_id\", StringType()),\n",
    "    StructField(\"adv_campaign_id\", StringType()),\n",
    "    StructField(\"adv_campaign_content\", StringType()),\n",
    "    StructField(\"adv_campaign_owner\", StringType()),\n",
    "    StructField(\"adv_campaign_owner_contact\", StringType()),\n",
    "    StructField(\"adv_campaign_datetime_start\", LongType()),\n",
    "    StructField(\"adv_campaign_datetime_end\", LongType()),\n",
    "    StructField(\"datetime_created\", LongType())\n",
    "])\n",
    "\n",
    "# определяем текущее время в UTC в миллисекундах, затем округляем до секунд\n",
    "current_timestamp_utc = unix_timestamp(current_timestamp()).cast(\"long\")\n",
    "\n",
    "# десериализуем из value сообщения json и фильтруем по времени старта и окончания акции\n",
    "filtered_read_stream_df = restaurant_read_stream_df \\\n",
    "    .select(from_json(col(\"value\").cast(\"string\"), incomming_message_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\") \\\n",
    "    .filter(\n",
    "        (current_timestamp_utc >= col(\"adv_campaign_datetime_start\")) & \n",
    "        (current_timestamp_utc <= col(\"adv_campaign_datetime_end\"))\n",
    "    )\n",
    "\n",
    "# вычитываем всех пользователей с подпиской на рестораны\n",
    "subscribers_restaurant_df = spark.read \\\n",
    "                    .format('jdbc') \\\n",
    "                    .option(\"url\", \"jdbc:postgresql://localhost:5432/de\") \\\n",
    "                    .option('driver', 'org.postgresql.Driver') \\\n",
    "                    .option('dbtable', 'subscribers_restaurants') \\\n",
    "                    .option('user', 'jovyan') \\\n",
    "                    .option('password', 'jovyan') \\\n",
    "                    .load()\n",
    "\n",
    "# джойним данные из сообщения Kafka с пользователями подписки по restaurant_id (uuid). Добавляем время создания события.\n",
    "subscribers_restaurant_df.printSchema()\n",
    "result_df = filtered_read_stream_df \\\n",
    "    .join(subscribers_restaurant_df, \"restaurant_id\", \"inner\") \\\n",
    "    .withColumn(\"trigger_datetime_created\", lit(current_timestamp_utc))\n",
    "\n",
    "# запускаем стриминг\n",
    "result_df.writeStream \\\n",
    "    .foreachBatch(foreach_batch_function) \\\n",
    "    .start() \\\n",
    "    .awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
